\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amsmath}
\title{CS146}
\author{Haria}
\date{October 2025}

\begin{document}

\maketitle

\section{Lecture 1 - Basic Notation}
\newtheorem{example}{Example}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

\subsection{Sums}
\subsubsection{Basic Sums}
Sigma notation makes use of the symbol $\displaystyle \sum$
Basic sigma notation makes use of of lower and upper bounds that a bound variable iterates through in order to represent the sum of multiple elements
\begin{example}
    \[\sum_{k=2}^{11}k! = 2! + 3! + 4! + 5! + \cdots + 10 ! + 11!\]
\end{example}
The lower bound is the initial condition and it ticks up by one to the upper bound and sums the expression with the values substituted in for the bound variable
\subsubsection{Sums over sets}
Instead of giving a range for the sum to sum over we can give it an arbitrary set of numbers to sum over
\begin{example}
    Let $A = \{1,2,\pi\}$
    \[\sum_{k \in A}2^{k^{2} - 1 } = 2^{1^{2} - 1} + 2^{2^{2} - 1} + 2^{\pi^{2} - 1}\]
\end{example}
If we let $E= \{2,4,6,8,\dots\}$ or be the set of even numbers we have two ways of expressing sums on this set
\[\sum_{k \in E}\frac{1}{2^k} = \sum_{k-even,k \ge 1}\frac{1}{2^k}\]
\subsubsection{Infinite Sums}
Some sums can have $\infty$ as their upper bound such as 
\[\sum_{k = 1}^{\infty}\frac{1}{2^k}\]
AS we know that the common ratio is in the radius of convergence, the infinite series is the limit of the partial sums. We know
\[\sum_{k = 1}^{n}x^k = \frac{1 - x^{n+1}}{1-x}\]
The infinite sum there for is the limit of this expression when $x$ is in the radius of convergence i.e $|x| < 1$
\[\lim_{n \to \infty}\sum_{k = 1}^{n}x^k = \lim_{n \to \infty}\frac{1 - x^{n+1}}{1-x} = \frac{1}{1-x}\]
\subsubsection{Empty Sums}
If we take a sum over the empty set it will always equal 0 (additive identity)
\[\sum_{k \in \emptyset}f(k) = 0\]
\subsection{Products}
Product notation works largely the same as summation notation and can be used for the expression of known functions such as the factorial
\[n! = \prod_{k = 1}^{n}k = 1 \times 2 \times \cdots \times n\]
We can also take products over a set. Let $X = \{1,2,3\}$
\[\prod_{k \in X}f(k) = f(1) \times f(2) \times (3)\]
We also have the fact a product over the empty set is 1 (multiplicative identity)
\[\prod_{k \in \emptyset}f(k) = 1\]
This also gives us the definition of $0! = 1$ as a sum from $1 \to 0$ is the same as a product over the empty set as there are no elements in that range
\subsection{Sets}
The first set we have is the natural numbers
\[\mathbb{N} = \{0,1,2,\dots\}\]
Note this definition includes zero which can be contentious. If we have $0 \in  \mathbb{N}$ then we can define the natural as such
\begin{itemize}
    \item $0 \in \mathbb{N}$
    \item $k \in \mathbb{N} \Rightarrow k + 1 \in \mathbb{N}$
\end{itemize}
This definition has a flaw as sets with more elements than just the natural numbers can fulfil this definition but it serves as a constructive definition.
\\
From the Natural Numbers (more so the integers which is just two copies of the naturals) we can define further sets
\[\mathbb{Q} = \left\{\frac{a}{b} : a \in \mathbb{Z},b \in \mathbb{Z},b \ne 0\right\}\]
And if we have the real numbers we can also define another set (defining the real numbers is the role of analysis)
\[\mathbb{C} = \left\{a + bi : a \in \mathbb{R},b \in \mathbb{R}\right\}\]
\section{Lecture 2 - Proofs}
\newtheorem{proposition}{Proposition}
Proofs are mathematical arguments that apply formal logical deductive steps to prove a proposition from a set of axioms.There are three general proof techniques being Direct proofs,Proof by Contradiction and Proof by Induction.
\subsection{DirectThe empty tuple is a value of () and it also has a type of ().
 Proof}
This is the simplest form of proof simply with direct application of arguments
\begin{proposition}
    For $n \ge 2$
    \[\sum_{k=2}^{n} = \frac{(n-1)(n-2)}{2}\]
\end{proposition}
\begin{proof}
    Fix $n \ge 2$ and let $S(n) = \sum_{k=2}^{n}$
    \[S(n) = 1 + 2 + \cdots + (n-1) + n\]
    \[S(n) = n + (n-1) + \cdots + 2 + 1\]
    \[2S(N) = (n+2) + (n + 2) + \cdots + (n+ 2) + (n + 2)\]
    \[2S(N) = (n-1)(n+2)\]
    \[S(n) = \frac{(n-1)(n+2)}{2}\]
\end{proof}
\subsection{Proof By Contradiction}
This techniques works by making the assumption of the negation of the proposition and from there deriving a contradiction
\begin{proposition}
    $\sqrt{2} \notin \mathbb{Q}$
\end{proposition}
\begin{proof}
    Assume that $\sqrt{2} \in \mathbb{Q}$ then there exists a coprime pair $x,y \in \mathbb{Z},y \ne 0$ such that $\sqrt{2} = \frac{x}{y}$
    \newline
    We can now say $x = 2y^{2}$
    \newline
    This suggest ${x^2}$ is even and there for $x$ is even therefore $x^2$ is a multiple of 4 meaning $y^2$ is even so $y $ is even so both $x,y$ share a factor of 2 and are as such not coprime yielding a contradiction so $\sqrt{2} \notin \mathbb{Q}$
\end{proof}
\section{Lecture 3 - Induction}
\subsection{Definitions}
An inductive proofs is a methods for proving things on ordered sets. This is most commonly $\mathbb{N}$ or $\mathbb{Z}^{+}$
\\
Let $C(n)$ be a predicate where $n \in \mathbb{N}$ then we know $\forall_{n \in \mathbb{N}}C(n)$ if we have 
\begin{enumerate}
    \item Base Case : $C(0)$
    \item Inductive Case : $C(k) \Rightarrow C(k+1)$
\end{enumerate}
\subsection{Example}
I have skipped the simple example and have instead skipped to the harder example.
\begin{proposition} \label{hard}
    Given $n \in \mathbb{Z}$ let $C(n) : n^3 - n \textit{ is divisible by three}$
\end{proposition}
Proposition \ref{hard} cant be done directly by induction as it is not well ordered (no least element for the base case). Instead we can split this into two problems. First we can prove is for $n \in \mathbb{N}$ then attempt to etend this proof to $\mathbb{Z}^-$.
\begin{proposition}
    Given $n \in \mathbb{N}$ let $C(n) : n^3 - n \textit{ is divisible by three}$
\end{proposition}
\begin{proof}
\phantom{HIII}
    \begin{itemize}
        \item Base Case : $C(0) : 0 \textit{ is divisible by three}$
        \item Inductive Case : (IH) $C(k) : k^3 - k \textit{ is divisible by three}$ , Aim : $C(k + 1) : (k + 1)^3 - (k + 1) \textit{ is divisible by three}$
        \begin{align*}
            (k+1)^3 - k &= k^3 + 3k^2 + 3k + k-1 \\
                        &= (k^3 - k) + 3(k^2 + k)
        \end{align*}
    \end{itemize}
    By the (IH) the first term is a multiple of three and adding it to another multiple of three gives overall a multiple of three.
\end{proof}
Now we want to extend this to negative integers
\begin{proof}
    We already know for $n \ge 0 : C(n) \textit{ is true}$, if $n \le 0$  then $n^3 - n = -((-n)^3 - (-n)$. The $(-n)$ terms are positive so the previous proof applies and the negative of a multiple of three is also a multiple of three.
\end{proof}
By combining both of these proofs we get a proof of Proposition \ref{hard}

\section{Lecture 4 - Recurrence}
\begin{definition}
    A recurrence relation is one where the sequence is defined in terms of previous terms. These will also generally have a base case.
\end{definition}
\begin{example}
    Consider the following sequence defined by series 
    \[a_n = \sum_{k=2}^{n}k = \frac{(n-1)(n+2)}{2}\]
    We can rewrite this as a recurrence relation as follows
    \[a_i = \begin{cases}
        2 ,&i=2 \\
        a_{i-1} ,&i>2
    \end{cases}\]
\end{example}
What we want is for a way to go from recurrence relations to closed forms. In order to do this lets consider the following recurrence
\[F_n = F_{n-1} + F_{n-2}\]
This will have boundary conditions $F_1 = 1$ and $F_2 = 1$. This can also be derived from a consideration of breeding pairs of rabbits. There is in general two methods that we can use to solve it, Characteristic polynomials and by generating functions (and a secret third way using matrices). Here we shall cover the first.
\subsection{Characteristic Polynomials}
\subsubsection{Fitting the recurrence}
WE start by assuming we have a solution of the form $\lambda^n$
\[\lambda^n = \lambda^{n-1} + \lambda^{n-2}\]
Assuming $\lambda \ne 0$ and rearranging we get
\[\lambda^2 - \lambda - 1 = 0\]
This yields two values for lambada of $\varphi$ and $\overline{\varphi}$ where $\varphi$ is the golden ratio. One thing to note is that neither of these though satisfy the boundary conditions.
\subsubsection{Boundary Conditions}
\begin{proposition}
    A linear combination of solutions to a recurrence relation is itself a solution.
\end{proposition}
\begin{proof}
    Here a proof for a second order relation is given but it is trivial to see how it generalises. Given a $\lambda_1$ and $\lambda_2$ such that 
    \[\lambda_1^n = s\lambda_1^{n-1} + r\lambda_1^{n-2}\]
    \[\lambda_2^n = s\lambda_2^{n-1} + r\lambda_2^{n-2}\]
    The terms
    \[\alpha\lambda_1^n + \beta\lambda_2^n\]
    Can be rewritten as 
    \[s(\alpha\lambda_1^{n-1} + \beta\lambda_2^{-1}) + r(\alpha\lambda_1^{n-2} + \beta\lambda_2^{n-2}\]
    By means of subbing in the fact they satisfy the relations. As such that can be seen to also satisfy the relation.
\end{proof}
\section{Lecture 5}
\subsection{Summary of the method}
The method is summarised as follows
\begin{itemize}
    \item Assume $\lambda^n$ is a solution
    \item Solve for lambda
    \item Take a general linear combination of these solutions
    \item  Solve against the boundary conditions
\end{itemize}
We can also express a generalised recurrence relation of order $k$ as follows
\[S_n = \sum_{r=1}^{k}a_rS_{k-r} + f(n)\]
This will come with $k$ boundary condition in order to be soluble
\subsection{Gaussian Elimination}
For higher order recurrence relations there will be n simultaneous equations to solve in order to fit to the boundary conditions. This can be slow so we would like an algorithmic method to be able to solve this. One such method is using Gaussian elimination. Gaussian elimination is concerned with the reduction of equations to triangular form. This is shown bellow.
\begin{align*}
    a_{1,n}x_n &= b_1 \\
    a_{2,n-1}x_{n - 1} + a_{2,n}x_n &= b_2 \\
    \cdots 
\end{align*}
The general idea is that the $k$th equation is expressed in terms of the last $k$ variables. The way this is done is by using the last equation to eliminate the first variable from each equation. Then the second last equation to eliminate the 2nd variable from the rest and so on. Once the entire process is done each variable is trivially solved for. \\
\textbf{WATCH A YOUTUBE VIDEO FROM THE ORGANIC CHEMISTRY TUTOR ON THIS}

\section{Lecture 6}
\subsection{Homogeneity}
As previously stated a general linear recurrence relation can be given as 
\[S_n = \sum_{r=1}^{k}a_rS_{k-r} + f(n)\]
If we have the fact that $f(n) \equiv 0$ we may say the equation is homogenous otherwise its non homogenous
\subsection{Complex roots}
Sometimes when solving for $\lambda$ we will find that it has complex values.
When this happens we have 3 solutions of what to do
\begin{enumerate}
    \item Just do it normally and solve for \[\alpha\lambda_1^n +\beta\lambda_2^n \]
    \item You can split alpha and beta into real and complex parts and solve for those separately \[(\alpha + \alpha'i)\lambda_1^n +(\beta +\beta'i)\lambda_2^n \]
    \item You can take advantage of the fact complex roots come in conjugate pairs and solve \[\alpha(\lambda_1^n + \lambda_2^n) + \beta(\lambda_1^n - \lambda_2^n)\] This has a closely related trigonometric form given as follows \[r^n(\alpha\cos n\theta + \beta \sin n \theta\]
    Where $r$ is the modulus of the root and $\theta$ is the argument. This is gotten by application of de Moivre's theorem.
\end{enumerate}
\section{Lecture 10}
\begin{example}
    \[Q_n = \begin{cases}
        4 &n=2 \\
        Q_{n-1} + n^2 &n \ge 3
    \end{cases}\]
    This has $s = 1$ and $d = 2$ where these are the orderes of the relation and the degree of the nonhomogenous section (polynmials).

    As such we have only one root $\lambda_1$ and expect the solution to look as follows 
    \[Q_n = \alpha_1 \lambda_1 + \sum_{i=0}^{2}\beta_i n^{i + \mu}\]
    From simple calculuation we know that $\lambda_1 = 1$ and this gives us also the $\mu = 1$ so 
    \[Q_n = \alpha + \beta_0n + \beta_1n^2 + \beta_2n^3\]
\end{example}
Consider the tower of hanoi where $h$ is the number of discs.If $h = 1$ it will take one moves. If $h \ge 2$ then you take $2H_{h-1} + 1$ moves where $H_h$ is the moves needed for $h$ discs. This allows us to generate a reccurence relation as follows
\[H_h = \begin{cases}
    1 & h = 1 \\
    2H_{h-1} + 1 & h \ge 2
\end{cases}\] 
Giving motivation to why non-homogenous reccurence relations are wanted to be solved.

When solving these non homegenous relations you may find you have not enough base cases in order to be able to solve for all of the coefficients. In the case that this has happened you use the reccurence relation in order to generate more definite cases.

We may want to consider informally why there is a polynomial term added on.
Consider the relation
\[B_n = \begin{cases}
    B_0 & n=1 \\
    B_{n-1} + p(n)
\end{cases}\]
We may consider a relation $B'_n$ which is the homogenous part of $B_n$. As the only difference between the two is continually adding $n$ we may say
\[B_n = B'_n + \sum_{k = 3}^{n}p(k)\]
As a sum of polynmials is itself a polynomial of we may observe that we would expect the solution to be the homogenous solution plus a non homgenous part.
\begin{example}
    \[B_n = \begin{cases}
    1 & n=1,2 \\
    5B_{n-1} - 6B_{n-2} + n
\end{cases}\]
Another considered tranformation is $B'_n = B_n + \alpha + \beta n$. Which represents a tranformation of the final solution removing the non homogenous parts of the solution. Suppose $n \ge 3$
\begin{align*}
    B'_n &= 5B_{n-1} - 6B_{n-2} + n + \alpha + \beta n \\
    &= 5(B'_{n-1} - \alpha - \beta(n-1)) - 6(B'_{n-2} - \alpha - \beta(n-2)) + n + \alpha + \beta \\
    &= 5B'_{n-1} - 6B'_{n-2} + 2\alpha - 7\beta + n(2 + \beta + n)
\end{align*}
Solving $\alpha,\beta$ to make the sequence homogenous corresponds to the solutons you would have gotten for solving the relation by the method given before
\end{example}
\section{Lecture 11}
Continuiong from the lat lecture for a non-homogenous relation $A_n$ with a polynomial non homgenous part of order $n$ we may consider the complementary relations $A'_n = A_n + g(n)$. Here $g(n)$ is some polynomial of deg at least $n$ so that it makes the reccurence for $A'_n$ homogenous. Once you have solved for the polynomial you then solve the homogenous part of the relation and use the tranform to get the solution to the non homogenous equation.
Consider the relation
\[Q_n = \begin{cases}
    4 &n = 2 \\
    Q_{n-1} + n^2 & n \ge 3 
\end{cases}\]
You may consider the transform $Q'_n = Q_n + \alpha + \beta n + \gamma n^2$ as for the linear case a linear transform worked so you may assume the same would carry forward.
\begin{align*}
    B'_n &= Q_{n-1} + n^2 + \alpha + \beta n + \gamma n^2 \\
    &=  Q'_{n-1} - \alpha - \beta (n-1) - \gamma (n-1)^2 + n^2 + \alpha + \beta n + \gamma n^2\\
    &= Q'_{n-1} + \beta + \gamma(2n - 1) + n^2 \\ 
\end{align*}
This is now impossible to make homogenous as we cannot eliminate the $n^2$ term.
By thinking back to the method for solving we can recall due to the root of 1 being present in the homogenous part the polynomial paert of the solution was shifted up by a factor of n such that the soltuion was a cubic. This is why $g$ is at least the degree of the polynomial part of the relation. For the above example above the appropriate transform would be $Q'_n = Q_n + \alpha + \beta n + \gamma n^2 + \delta n^3$. In order to fomrally prove such notion we need to look at some more maths.
\subsection{Falling Power}
\begin{definition}
    Let the order $m$ falling power be given by
    \[x^{\underline{m}} = x \cdot (x - 1) \cdot \dots \cdot (x - m + 1) = \prod_{k = 1}^{m}(x - k + 1) = \frac{x!}{(x-m)!}\]
    Note $x^{\underline{0}} = 1$
\end{definition}
\begin{theorem}
    Suppose $p(x)$ is a polynomial of degree $n$. There are unioque numbers $a_0,\dots,a_d$ such that
    \[p(x) = \sum_{k = 0}^{d} a_k x^{\underline{k}}\] 
\end{theorem}
\begin{proof}
    We will take induction on n and appreciate that
    \[p(x) = \sum_{k = 0}^{d} \beta_k x^k\]
    Base Case: $d = 0$

    \[p(x) = \beta_0 = \beta_0 x^0 = \beta_0 x^{\underline{0}}\]
    So true
    
    Inductive Step : Suppose $d > 0$ and for any polynomial of degree $f \le d - 1$ that the aim is true.
    \[p(x) = \sum_{k = 0}^{d} a_k x^{\underline{k}}\].
    Let $\alpha_d = \beta_d$ and let $q(x) = p(x) - \alpha_d x^{\underline{d}}$ which is a degree of order at most $d-1$ as the terms of order $d$ cancel out as their coefficients are the same but negative. By the hypothesis $q(x)$ can be shown as falling powers up do $d-1$. And as $q(x) +  \alpha_d x^{\underline{d}} = p(x)$
    \begin{align*}
        p(x) &= q(x) +  \alpha_d x^{\underline{d}} \\
        &= \sum_{k = 0}^{d-1} a_k x^{\underline{k}} + \alpha_d x^{\underline{d}}\\
        &= \sum_{k = 0}^{d} a_k x^{\underline{k}}
    \end{align*}
\end{proof}
\section{Lecture 12}
\subsection{difference operator $\Delta$}
This operation is somewhat the discrete analogue of the derivative
\begin{definition}
    LEt $f : \mathbb{N} \to \mathbb{R}$ we may define fhte difference ($\Delta$) as follows
    \[(\Delta f)(n) = f(n + 1) - f(n)\]
\end{definition}
\begin{example}
    Consider a function $f:\mathbb{N} \to \mathbb{R}$ such that $f(x) = x^3$. 
    \begin{align*}
        (\Delta f)(n) &= (n + 1)^3 - n^3 \\
        &= 3n^2 + 3n + 1
    \end{align*}
\end{example}
The difference operator also satsifies linearity allowing it to distrobute over the sum of functions.
\begin{proposition}
    For any function $f : \mathbb{N} \to \mathbb{R}$
    \[f(n) = f(1) + \sum_{k = 1}^{n - 1}(\Delta f)(k)\]
\end{proposition}
This can be considered the discrete analogue of the fundamental theorem of calculus.  this version of the proposition assumes that $0 \not \in \mathbb{N}$. If you do include zero swap 1 for 0
\begin{proof}
    \begin{align*}
        f(1) + \sum_{k = 1}^{n - 1}(\Delta f)(k) &= f(1) + \sum_{k = 1}^{n - 1}f(k + 1) - f(k) \\
        &= f(1) + \sum_{k = 1}^{n-1}f(k+1) - \sum_{k = 1}^{n - 1}f(k) \\
        &= f(1) + \sum_{k = 2}^{n}f(k) - \sum_{k=1}^{n-1}f(k) \\
        &= f(1) + f(n) - f(1) \\
        &= f(n) 
    \end{align*}
\end{proof}
The trick used in order to casncel down the sum is known as telescopic.
\begin{proposition}
    Product rule : Let there be a function $f : \mathbb{N} \to \mathbb{R}$
    \[(\Delta f \cdot g)(x) = (\Delta f)(x)g(x + 1) + f(x)(\Delta g)(x)\]
\end{proposition}
\begin{proof}
    \begin{align*}
        & (\Delta f)(x)g(x + 1) + f(x)(\Delta g)(x)\\ 
        &= (f(x+1) - f(x))g(x + 1) + f(x)(g(x + 1) - g(x)) \\
        &= f(x+1)g(x+1) - f(x)g(x + 1) + f(x)g(x + 1) - f(x)g(x) \\
        &= f(x+1)g(x+1) - f(x)g(x) \\
        &= (\Delta f \cdot g)(x)
    \end{align*}
\end{proof}
\subsection{Combining the two}
\begin{proposition}
    Falling Power rule : $(\Delta)x^{\underline{m}} = mx^{\underline{m - 1}}$. Where $m \ge 1$
\end{proposition}
\begin{proof}
    We will do this proof by induction on $m$. With $m \ge 1$
    \begin{itemize}
        \item Base case $m=1$
        \[\Delta x^{\underline{1}} = (x + 1) - x = 1 = 1x^{\underline{0}}\]
        \item Inductive Step. Assume it holds for some $m \ge 1$. We now aim to show it for $m + 1$
        \begin{align*}
            \Delta x^{\underline{m + 1}} &= \Delta (x^{\underline{1}} \cdot (x - 1)^{\underline{m}}) \\
            &= (x + 1 - x)(x - 1 + 1)^{\underline{m}} + x \cdot (\delta (x - 1)^{\underline{m}}) \\
            &= (x )^{\underline{m}} + x \cdot m(x - 1)^{\underline{m - 1}} \\
            &= (x )^{\underline{m}} + m(x )^{\underline{m}} \\
            &=  (m + 1)(x )^{\underline{m}}
        \end{align*}  
    \end{itemize}
\end{proof}
\section{Lecture 15}
Suppose we have a set $A$ such that $|A| = n \in \mathbb{N}$ how many subsets are there of size $k$. This is given by the binomial coefficients as $\binom{n}{k}$
\begin{proposition}
    Suppose $A$ is a set such that $|A| = n \in \mathbb{N}$ the numer of ways this can be ordered is $n!$.
\end{proposition}
\begin{proof}
    There are $n$ position we are able to place in the elements.
    \begin{itemize}
        \item For the first position we have $n$ options 
        \item For the second position we have $n - 1$ options
        \item $\cdots$
        \item For the $(i + 1)$th position we have $n - i$ options
        \item $\cdots$ 
        \item For the $n$th position we have 1 choice
    \end{itemize}
    By the product rule for combinatorics (also known as the fundamental principle of counting) we may take the product of all of these will give us the total number of orderings which is 
    \[n \times (n - 1) \times \cdot \times 2 \times 1 = n!\]
\end{proof}
We can firther generalise this proposition
\begin{proposition}
    Suppose $A$ is a set such that $|A| = n \in \mathbb{N}$ the number of ordering of length $k$ $\frac{n!}{(n - k)!}$.
\end{proposition}
\begin{proof}
    There are $k$ position we are able to place in the elements.
    \begin{itemize}
        \item For the first position we have $n$ options 
        \item For the second position we have $n - 1$ options
        \item $\cdots$
        \item For the $(i + 1)$th position we have $n - i$ options
        \item $\cdots$ 
        \item For the $k$th position we have $(n - (k - 1))$ choices
    \end{itemize}
    By the product rule for combinatorics (also known as the fundamental principle of counting) we may take the product of all of these will give us the total number of orderings which is 
    \[n \times (n - 1) \times \cdot \times (n - k + 1)= \frac{n!}{(n - k)!}\]
\end{proof}
Now we return to the first claim and aim to prove this
\begin{proposition}
    The number of $k$-element subsets of a set $a$ such that $|A| = n  \in \mathbb{N}$ 
    \[\binom{n}{k} = \frac{n!}{(n - k)!}\]
\end{proposition}
\begin{proof}
    Suppose $|A| = n \in \mathbb{N}$. We can call $N_k$ the number of $k$ element subsets of $A$.

    We can make the observation for each $k$ elements subset $B \subseteq A$ the number of orderings of $B$ is $k!$. From here we can define a set $\Gamma$ such that for all $B$  $\Gamma$ contains all of the orderings of $B$.
    Therefore we can say $|\Gamma| = k!N_k$
    $\Gamma$ is also the set of orderings of elements of $k$ elements so we can also say $\Gamma = \frac{n!}{(n - k)!}$
    And as such we can conclude
    \begin{align*}
        k!N_k &= \frac{n!}{(n - k)!} \\
        N_k &= \frac{n!}{k!(n - k)!} = \binom{n}{k}
    \end{align*}
\end{proof}
\begin{proposition}
    for all $x,y \in \mathbb{R}$ and $n \ge 0$
    \[(x + y)^n = \sum_{0}^{n}\binom{n}{k}x^ny^{n - k}\]
\end{proposition}
\begin{proof}
    We may expand the bonomial as 
    \[\underbrace{(x+ y)(x+y)\cdots(x+y)}_{n \text{ times}}\]
    Each monomial is made up by choosing one of $x,y$ from each parenthesis. For a specifc monomial $x^ny^{n - k}$ The coefficient is the number of ways we can choose $x$ from the $n$ parenthesesis. This value is $\binom{n}{k}$ which becomes the coefficient of each monomial.
\end{proof}
\section{Lecture 16}
We have already shown the following theorem for 2 sets
\begin{theorem}
    For any two finite sets 
    \[|A \cup B| = |A| + |B| - |A \cap B|\]
\end{theorem}
This can be generalised to
\begin{theorem}
    For a sequence of finite sets $(A_n)$ of length greater than 2 we may say
    \[\left|\bigcup_{k = 1}^{n}A_k\right| = \sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset}(-1^{|I| + 1})\left|\bigcap_{S \in I}A_S\right|\]
\end{theorem}
\begin{proof}
    We may make attempt to prove this by induciton on $n$.
    \begin{itemize}
        \item Base case $n = 2$
        \[|A_1 \cup A_2| = |A_1| + |A_2| - |A_1 \cap A_2|\]
        Which we already know to be true so the base case holds
        \item Inductive Step: We may assume the statement holds for some $n\ge 2$. We aim t o show that it is true for $n+1$
        
        \begin{align*}
            \left|\bigcup_{k = 1}^n A_k\right| &= \left|A_{n + 1} \cup \bigcup_{k = 1}^n A_k\right| \\
            &= |A_{n+1}| + \left|\bigcup_{k = 1}^n A_k\right| - \left|A_{n + 1} \cap \bigcup_{k = 1}^n A_k \right| \\
            &= |A_{n+1}| + \left|\bigcup_{k = 1}^n A_k\right| - \left|\bigcup_{k = 1}^n A_k \cap A_{n + 1}\right|  \\
            &= |A_{n+1}| + \sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset}(-1^{|I| + 1})\left|\bigcap_{S \in I}A_S\right|\\
            & - \sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset}(-1^{|I| + 1})\left|\bigcap_{S \in (I \cup \{n + 1\})}A_S\right|
        \end{align*}
        The expression is already getting quite long and evil. We will now make a series of dummy variables and sunbin order to make this expressions easier to simplify. Consider the part of the expression 
        \[\sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset}(-1^{|I| + 1})\left|\bigcap_{S \in (I \cup \{n + 1\})}A_S\right|\]
        We may introduce a variable $J$ such that $J = I \cup \{n + 1\}$ allowing us to reqrite as follows
        \[\sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset,J = I \cup \{n + 1\}}(-1^{|J|})\left|\bigcap_{S \in J}A_S\right|\]
        Then we can try to reintroduce the plus in the power.
        \[-\sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset,J = I \cup \{n + 1\}}(-1^{|J| + 1})\left|\bigcap_{S \in J}A_S\right|\]
        This leaves our expression as follows
        \[\sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset}(-1^{|I| + 1})\left|\bigcap_{S \in I}A_S\right| + \sum_{I \subseteq \{1,\dots,n\},I \ne \emptyset,J = I \cup \{n + 1\}}(-1^{|J| + 1})\left|\bigcap_{S \in J}A_S\right|\]
        And we want to consider how to comine these two expression. If we consider subsets of $\{1,\dots,n+1\}$ we can not the fitrst sum is all subsets such that $n + 1$ is in it and the second contains all that dont so we may comine them as follows and adding on the first term to ensure we get the singluar $A_{n + 1}$ term we get the following
        \[\sum_{I \subseteq \{1,\dots,n+1\},I \ne \emptyset}(-1^{|I| + 1})\left|\bigcap_{S \in I}A_S\right|\]
    \end{itemize} 
\end{proof}
\section{Lecture 20}
Preimage is denoted $f^{(-1)}(x)$ which gives a set
We can induce relations from functions $f(s) = t \iff sRt$
Not every relation is a function as each $r$ relates to exactly one $t$
\begin{definition}
    Injective: Here is an alternate way to denote injectivity. Given an $f : A \to B$ for all $b \in B,|f^{(-1)}(b)| \le 1$
\end{definition}
\begin{definition}
    Surjectivity: Similarly surjectivity can be redifined as follows Given an $f : A \to B$ for all $b \in B,|f^{(-1)}(b)| \ge 1$ 
\end{definition}
\begin{definition}
    Bijectivity: And from here it follows that bijectivity is Given an $f : A \to B$ for all $b \in B,|f^{(-1)}(b)| = 1$
\end{definition}
\section{Lecture 21}
\begin{definition}
    For functions from $f,g : \mathbb{N} \to \mathbb{R}^{+}$ we say that $f \in O(g)$ if there exists a $k$ such that $f(x) \le kg(x)$
\end{definition}
An eqiuvalent defintion may be given as 
\begin{definition}
    For functions from $f,g : \mathbb{N} \to \mathbb{R}^{+}$ we say that $f \in O(g)$ if there exists a $n_0,k$ such that $f(n) \le kg(n)$ for all $n \ge n_0$
\end{definition}
\begin{proposition}
    Consider the limit
    \[\lim_{n \to \infty} \frac{f(n)}{g(n)}\]
    If this converges to a finite limit we may say that $f \in O(g)$. IF this limit diverges to infity we may say that $f \not \in O(g)$
\end{proposition}
\begin{proof}
    Let us start with the proof in the case of a finite limit. Consider there limit to be a value $L \ge 0$. We can then say there is an $n_0$ such that for all $n \ge n_0$
    \[\left|\frac{f(n)}{g(n)} - L\right| \le \varepsilon\]
    We may now let $\varepsilon = 1$ and allow $n_0$ to be set accordingly. we may then deduce
    \[-1 \le \frac{f(n)}{g(n)} - L \le 1\]
    and it follows then that
    \[f(n) \le (L + 1)g(n)\]
    For $n \ge n_0$ which satisfies the definition.

    Now lets approach the infite divergence case. In this case we can make the statement for all $L \ge 0$ there exists and $n_0$ such that for all $n \ge n_0$
    \[\frac{f(n)}{g(n)} > L\]
    Suppose for the sake of contradiction that we have the limit is $+\infty$ and that $f \in O(g)$. We may say then that there is a $k$ such that $f(n) \le kg(n)$ by definition.
    We may then let $L = K$ which implies by the definition of divergence to infity that $f(n) > kg(n)$ for $n > n_0$ This means when $n_0 > n$ we have that $f(n) > kg(n)$ and $f(n) \le kg(n)$ whcih is a contradsiction. 
\end{proof}
\begin{proposition}
    Suppose that some function $f : \mathbb{N} \to \mathbb{R}^+$ can be written as follows
    \[f(n) = \sum_{i = 1}^{c}f_i(n)\]
    Where $f_i : \mathbb{N} \to \mathbb{R}^+$ for all $i$.
    We may say
    \begin{enumerate}
        \item If all $f_i \in O(g)$ then $f \in O(g)$
        \item If there exists an $f_i \not \in O(g)$ then $f \not \in O(g)$
    \end{enumerate}
\end{proposition}
\begin{proof}
    \begin{enumerate}
        \item We may say that for all $f_i$ there is a $k_i$ such that $f_i(n) \le k_ig(n)$
        As such we may say the following
        \[f(n) = \sum_{i = 1}^{c}f_i(n) \le g(n)\sum_{i = 1}^{c}k_i\]
        As the sum is a finite sum of constants it is itself a constant so we can not that $f \in O(g)$
    \end{enumerate}
\end{proof}
\section{Lectuire 28}
Some reccurence relations do not have/have very cursed closed form solutions but we still want to quantify their behaviour. As such we can use asymptotics to measure theier behaviour
\subsection{Direct Method}
Consider the runtime analysis of merge sort
\[T(n) = \begin{cases}
    1 & n = 1 \\
    4n + T(\left\lceil n/2 \right\rceil) + T(\left\lfloor n/2 \right\rfloor ) & n > 1
\end{cases}\]
This can be hard to form a closed form for. 
\begin{proposition}
    $T(n)$ is monotone increasing (wrt $n$)
\end{proposition}
\begin{proof}
    Aim : $T(n) \ge T(n+1)$
    
    We will attempt strong induction on $n$
    \begin{itemize}
        \item Base Case : $T(1) = 1,T(2) = 10$. We can note $10 > 2$ So the base of induction holds
        \item inductive Case Assume for some $m > 1$ that the inequality holds for all $n < m$. We aim to prove it for $n = m$
        \begin{align*}
            T(m + 1) &= 4(m + 1) + T(\left\lfloor \frac{m+1}{2}\right\rfloor) + T(\left\lceil \frac{m+1}{2}\right\rceil ) \\
            &> 4m + T(\left\lfloor \frac{m}{2}\right\rfloor) + T(\left\lceil \frac{m}{2}\right\rceil ) \\
            &= T(m)
        \end{align*}
        So we may conclude $T(m + 1) > T(m)$
    \end{itemize}
\end{proof}
Note that when we restrict $n = 2^k,k\in\mathbb{N}$ the reccurence is simpler
\[T(2^k) = 2^{k+2} + 2T(2^{k-1})\]
We also know for every other $n$ we have that $2^k \le n \le 2^{k+1}$ Where $k = \left\lfloor \log_2(n)\right\rfloor$
In order to solve this we create an auxiliary reccurence satisfying $T'(k) = T'(2^k)$
\[T'(k) = \begin{cases}
    1 &k=0 \\
    2^{k+2} + 2T'(k-1) & K \ge 1
\end{cases}\]
Suppose then $k$ is large we may show the expansion of terms looks akin to 
\[T'(k) = cT^{n + 2} + 2^{c}T'(n - c)\]
This is easily proven by induction. Letting $c = k$ and then substituting back we get
\[T(n) = n(4\log_2(n) + 1)\]
Using this form for powers of $n$ we can reavluate the upper and lower bounds
\begin{align*}
    T(n) &\ge T(2^{\left\lfloor \log_2(n)\right\rfloor}) \\
    &= 2^{\left\lfloor \log_2(n)\right\rfloor} \cdot (4\left\lfloor \log_2(n)\right\rfloor + 1) \\
    &\ge 2^{\log_2(n) - 1} \cdot (4(\log_2(n) - 1) + 1) \\
    &= 2n\log_2(n) - \frac{3}{2}n 
\end{align*}
Through a similar chain of reasoning we can determine
\[T(n) < 8n\log_2(n) + 10n\]
So $T(n)$ can be bounded as follows
\[2n\log_2(n) - \frac{3}{2}n \le T(n) < 8n\log_2(n) + 10n\]
and therefore 
\[\frac{1}{2}n\log_2(n) \le T(n) < 18n\log_2(n)\]
As such we may conclude $T(n) \in \Theta(n\log_2(n)))$
\end{document}
