\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[utf8]{inputenc}

\usepackage{kpfonts}
\usepackage{newunicodechar}

\newunicodechar{¬}{\TextOrMath{\textlnot}{\lnot}}
\title{ST120}
\author{Haria}
\date{October 2025}

\begin{document}

\maketitle

\section{Lectures 1 + 2}
\subsection{Probability Spaces}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
Consider a simple probability problem. I have a bag with 20 balls of three different colours 4 red balls 6 blue balls and 10 green balls. A simple question to be asked is what is $\mathbb{P}(\text{red})$. From intuition you know this number is $\frac{4}{20}$ but it is important to formalise what's going on.
\subsubsection{Sample Space}
We can say that red green and blue are three $\textbf{outcomes}$ that can occur. It can be useful to collect these three events together into a set as such $\{\text{red},\text{blue},\text{green}\}$.
\begin{definition}
    Let $\Omega$ denote the Sample Space, The set of all outcomes.
\end{definition}
\subsubsection{Event Space}
Sometimes we want to discuss what we call and even instead of a specific outcome. Sometimes we may want to ask what is $\mathbb{P}(¬ \text{red})$ we can associate ¬red with the set $\{ \text{blue}, \text{green}\}$. We call such a thing event and events are sets of outcomes and as such every event is a subset of the Sample Space
\begin{definition}
    Let $\mathcal{F}$ denote the Event Space. The Set of all events. $\mathcal{F} \subseteq \mathcal{P}(\Omega)$
\end{definition}
\subsubsection{Probability Map}
The last thing we want to do is be bale to go from an event to the actual probability.
\begin{definition}
    Let $\mathbb{P}$ denote the probability map. It is a function $\mathcal{F} \to [0,1]$ associating an event with a probability
\end{definition}
Such a map should fulfil some list of properties as follows
\begin{itemize}
    \item $\mathbb{P}({\emptyset}) = 0$
    \item $\mathbb{P}(\Omega) = 1$
    \item For any events $A,B \in \mathcal{F}$ where $A \cap B = \emptyset $ then $\mathbb{P}(A) + \mathbb{P}(B) = \mathbb{P}(A \cup B)$
\end{itemize}



\begin{definition}
    A Probability Space is the triple $(\Omega,\mathcal{F},\mathbb{P})$
\end{definition}
\subsection{Uniform Probability Spaces}
\begin{definition}
    A uniform probability space is a triple $(\Omega,\mathcal{F},\mathbb{P})$  satisfying the normal properties aswell as a uniformity where for any $\omega,\omega' \in \Omega$ we have $\mathbb{P}(\omega) = \mathbb{P}(\omega')$
\end{definition}
As such we conject that $\mathbb{P}(A) \propto |A|$
\begin{proposition}
    Let $(\Omega,\mathcal{F},\mathbb{P})$ denote a UPS then for all $\omega \in \Omega$ $\mathbb{P}(\{\omega\}) = \frac{1}{|\Omega|}$ 
\end{proposition}
\begin{proof}
    Since for all $\omega,\omega' \in \Omega$ we have $\mathbb{P}(\omega) = \mathbb{P}(\omega')$  let $p = \mathbb{P}(\omega)$
    \[1 = \mathbb{P}(\Omega) = \sum_{\omega \in \Omega}\mathbb{P}(\omega)\ = \sum_{\omega \in \Omega}p = p|\Omega|\]
    \[p = \frac{1}{|\Omega|}\]
\end{proof}
\begin{proposition}
    Let $(\Omega,\mathcal{F},\mathbb{P})$ denote a UPS then for all $A \in \mathcal{F}$ $\mathbb{P}(A) = \frac{|A|}{|\Omega|}$ 
\end{proposition}
\begin{proof}
    \[\mathbb{P}(A) =  \sum_{\omega \in A}\mathbb{P}(\omega) = p|A| = \frac{|A|}{|\Omega|}\]
\end{proof}
\subsection{Basics of Combinatorics}
Here we shall present the Fundamental rules of counting
\begin{itemize}
    \item Correspondence Rule : If $A$ and $B$ are in 1 - 1 correspondence then $|A| = |B|$
    \item Addition Rule : if $A_{1},A_{2},\dots,A_{n}$ are pairwise disjoint then
          \[\left|\bigcup_{i=1}^{n}A_{i} \right| = \sum_{i=1}^{n}|A_{i}|\]
        \item Fundamental Counting Principle : Suppose a finite set $E$ can have its elements determined in $k$ successive steps with $n_{i}$ possibilities for each step $1,\dots,k$ and different choices lead to different elements then $|E| = \prod_{i = 1}^k n_{i}$  
\end{itemize}

\section{Lecture 3 - Birthdays Problems}
We have started to build up a theory for how to calculate probabilities. Now we will try to apply these and also see whatever definitions are needed to fill in the gaps
\subsection{Tuples and Orderings}
\subsubsection{Tuples}
The first problem we will attempt to solve is "What is the probability, given a room of 30 people, that at least two of them share a birthday/ The first thing we will want to identify is what is the sample space. The sample space intuitively should be the space of all configurations of birthdays the group can have. Naturally this forms a uniform probability space as each outcome is equally likely. We also have to consider how to mathematically represent these outcomes so that we can find the size of the entire sample space. The way we shall represent these are as 30-tuples $(b_{1},b_{2},\dots,b_{30})$ where $b_{i}$ is the $i$th persons birthday.

Now lets discuss what a tuple is
\begin{definition}
    Given a set $A$ such that $|A| = n \in \mathbb{N}$. A sequence of length $k \in \mathbb{N}$ of elements of $A$ is an ordered $k$-tuple $(a_1,\dots a_k)$ such that $a_i \in A$ where $i \in \{1,\dots,k\}$   
    We denote these sequences $S_{n,k}(A)$
\end{definition}
Now we need to be able to compute the cardinality of sets of sequences
\begin{proposition}
    For a set $A$ where $|A| = n \in \mathbb{N}$
    \[|S_{n,k}(A)| = n^k\]
\end{proposition}
\begin{proof}
    To construct an arbitrary element of $S_{n,k}(A)$ we first choose $a_1$ for which we have $n$ options then we choose $a_2$ for which we have $n$ options and so on up till $n_k$ where we have $n$ options. As each option provides a different element in the final set we can use the fundamental principal of counting to compute the size. 
    \[|S_{n,k}(A)| = \underbrace{n\times n \times \dots \times n}_{k \text{ times}} = n^k\]
\end{proof}
Using this result we can find the size of the sample space in the birthdays problem as $|\Omega| = 365 ^ {30}$ 
\subsubsection{Orderings}
Next we wish to compute the cardinality of the event "\textit{At least two people share a birthday}". Much easier than computing this is to compute the complementary event "\textit{No two people share a birthday}". this means that each tuple in this event has no repeated elements. this is what we call and ordering.
\begin{definition}
    Given a set $A$ such that $|A| = n \in \mathbb{N}$ and a $k \le n$ we can say and ordering of length $k$ of elements of $A$ is a sequence of length $k$ of a with no repetition. We denote these $O_{n,k}(A)$
    \[O_{n,k}(A) = (a_1,\dots,a_k) : a_i \in A,\forall_{i,j}\text{ }a_i \ne a_j\]
\end{definition}
Now we would also like to be able to compute the sizes of sets of orderings.
\begin{proposition}
    Given a set $A$ such that $|A| = n \in \mathbb{N}$ and a k such that $k \le n$
    \[|O_{n,k}(A)| = \frac{n!}{(n-k)!}\]
\end{proposition}
\begin{proof}
    We can determine elements of $O_{n,k}$ elements by element. To determine $a_1$ we have $n$ choices. For the $a_2$ we have $n-1$ choices as we cant repeat the first element. For $a_k$ we have $n - (k+1)$ choices. As each series of choices leads to a different element we can apply the fundamental principle of counting.
    \[|O_{n,k}(A)| =n \times (n-1) \times \cdots \times (n - k +1)_= \frac{n!}{(n-k)!}\]
\end{proof}
So if we let $B$ denote the event no one shares a birthday then
$B = O_{365,30}(\text{365 days})$ so $|B| = 365 \times \cdots \times (365 - 30 + 1)$ so 
\[\mathbb{P}(B) = \frac{|B|}{|\Omega|} \approx 0.29\]
So we then have for our original event that at least 2 people share a probability of about 0.71.
\subsection{Another Example}
Now lets consider a similar problem of there being \textbf{exactly} 2 people sharing a birthday. We can characterize each outcome in our desired event by three characteristics
\begin{enumerate}
    \item The two people who share a birthday
    \item The day that they share
    \item The days everyone else has
\end{enumerate}
Now to compute the size of the event by the fundamental principle of counting we need to compute the number of choices for each piece of information.
\begin{enumerate}
    \item An intuitive guess for the first one is $|O_{30,2}|$ but this cares about the order that the two people share a birthday are picked in which doesn't really matter so we can divide this by the ways to order the two yielding us \[\frac{|O_{30,2}|}{|O_{2,2}|} = \frac{30!}{28!2!}\]
    \item There are 365 possibilities for this day
    \item For the remaining 28 people by the Fundamental Counting Principle we have $364 \times \cdots \times(365-28)$ 
\end{enumerate}
Now via computation and the same sample space as before we get the probability is roughly 0.28
\subsection{Combinations}
\begin{definition}
    Let $A$ be a set such that $|A| = n  \in \mathbb{N}$. We can say that a combination of $k$ elements of $A$ is a subset of $A$ with $k$ elements. Let the set of combinations be denoted $C_{n,k}(A)$
\end{definition}
\begin{proposition}
    Let $A$ be a set such that $|A| = n  \in \mathbb{N}$ and $k \le n$
    \[|C_{n,k}(A)| = {{n}\choose{k}}\]
\end{proposition}
\begin{proof}
    On ordering of length $k$ can be obtained uniquely in the following steps.
    \begin{enumerate}
        \item Choose from $C_{n,k}(A)$. This gives $|C_{n,k}(A)|$ choices 
        \item Choose a permutation of these. $k!$ choices.
    \end{enumerate}
    By the FPC we get 
    \[|O_{n,k}(A)| = k!|C_{n,k}(A)|\]
    By rearranging we can get
    \[|C_{n,k}(A)| = \frac{n!}{(n-k)!k!} = {n\choose{k}}\]
\end{proof}

As an exemplar problem we can consider all the ways that, having rolled 8 fair dice, our outcome has three twos, three fours and two fives. We can note that each of our valid outcomes is uniquely characterised by what dice gives us the twos and fours. Initially we have $8\choose{3}$ positions for the twos then $5\choose{3}$ for the fours and the fives must go where is left. By the FPC this event has size being the product of these two numbers 
\section{Lecture 4 - Partitions}
\begin{definition}
    Let $A$ be a set such that $|A| = n\in \mathbb{N}$ and let $r \le n$. \\
    An ordered parttion of $A$ into $r$ ordered subsets of cardinalt $k_1,\dots , k_r$ is a sequence of $(A_1,\dots,A_r)$ such that $|A_i| = k_i$, all the elements are pairwise disjoint and $\bigcup_{i=1}^rA_i = A$
\end{definition}
\begin{proposition}
    LEt $A$ be a set such that $|A| = n \in \mathbb{N}$ and $r \le n$. The number of partitions of $A$ into $r$ subsets of cardinality $k_1,\dots,k_r$ is \[\frac{n!}{k_1!\times\cdots k_r!}\]
\end{proposition}
\begin{proof}
    We can determine a partition as follows \\
    Choose elements as follows
    \begin{align*}
        A_1 \subseteq A \text{ such that} |A_1| = k_1 &\text{ gives } {n\choose{k_1}} \\
        A_1 \subseteq A \text{\textbackslash} A_1 \text{ such that} |A_1| = k_1 &\text{ gives } {{n - k_1}\choose{k_2}} \\
        \cdots &\\
        A_1 \subseteq A \text{\textbackslash} \bigcup_{i = 1}^{r-1}A_i \text{ such that} |A_1| = k_1 &\text{ gives } {{n - \sum_{i = 1}^{r-1}k}\choose{k_r}} \\
    \end{align*}
    By application of the fundamental priniple of counting and some carful counting we get the amount of partitions is \[\frac{n!}{k_1!\times\cdots k_r!}\]
\end{proof}
\subsection{Samplings}
Sampling is how we produce realisations of random variables.
\subsubsection{Example 1}
Imagine a population of size $n \in \mathbb{N}$ and there are $n_1$ type 1 individuals and $n_2$ type two individuals.\\
Suppose we draw a sample of size $k \le n$ from the population without replacement. The probability of a sample containing $k_1$ type one individuals and $k_2 = k - k_1$ of type 2 is 
\[\]
\section{Lectrue 5 - General Probability Spaces}
We have spent a while specifically discussing uniform probability spaces. There are some more gnerealisations we may want to make to how our space works
\begin{itemize}
    \item Let $\Omega$ be an arbitrary set
    \item Allow $\mathcal{F}$ to reflect partial knowledge
    \item Following from the previous point we want to appreciate that $\mathcal{F} = \mathcal{P}(\Omega)$ is not always feasible.
    \item Finally we want to define porperties of $\mathbb{P}$ on general $\mathcal{F}$
\end{itemize}
\subsection{Sample and Event Spaces}
\begin{definition}
    $\Omega$ is the set of all possible outcomes for a propabalistic process.
\end{definition}
In this course three cases are covered
\begin{itemize}
    \item $|\Omega| = n \in \mathbb{N}$
    \item $|\Omega| = |\mathbb{N}|$
    \item $|\Omega| = |\mathbb{R}|$
    \begin{definition}
        $\mathcal{F}$ is the event space and contains collections of outcomes for which you can make a judgement on wether the event happened or not
    \end{definition}
\end{itemize}
\begin{example}
    Imagine roilling a dice $\Omega = \{1,2,3,4,5,6\}$. The only information you are told is whether or not the outcome is odd or even. As this is the only information you are given you cannot diffrentiate the events $\{2\}$ and $\{4\}$. As such they cannot be in the event space. Here $\mathcal{F} = \{\emptyset,\{1,3,5\},\{2,4,6\}\}$.
\end{example}
Now lets present a more formal definition of the event space
\begin{definition}
    Let $\Omega$ be a sample scpae and $\mathcal{F} \subseteq \mathcal{P}(\Omega)$ \\
    We can say $\mathcal{F}$ is an event space iff
    \begin{enumerate}
        \item $\Omega \in \mathcal{F}$ , $\emptyset \in \mathcal{F}$
        \item If $A \subseteq \Omega$ and $A \in \mathcal{F}$ then $A^C \in \mathcal{F}$ (closure under complements)
        \item Given a set $A = \{A_n \in \mathcal{F}| n \in \mathbb{N}\}$ then $\bigcup_{n=1}^{\infty}A_n \in \mathcal{F}$ (closure ubder coubntable union)
    \end{enumerate}
\end{definition}
\begin{proposition}
    $\Omega \ne \emptyset$ and $\mathcal{F} = \mathcal{P}(\Omega)$ then $\mathcal{F}$ is an event space
\end{proposition}
\begin{proof}
    \begin{enumerate}
        \item $\Omega \in \Omega \Rightarrow\Omega \in P(\Omega) = \mathcal{F}$
        \item $A \subseteq \Omega,A \in \mathcal{F}$ then $A^C = \Omega\text{\textbackslash}A \subseteq \Omega \Rightarrow A^C \in \mathcal{P}(\Omega) = \mathcal{F}$
        \item Consider $A = \{A_n \in \mathcal{F}| n \in \mathbb{N}\}$
        \[\bigcup_{A_n \in A}A_n \subseteq \bigcup_{A_n \in A}\Omega = \Omega \in \mathcal{P}(\Omega) = \mathcal{F} \]
    \end{enumerate}
\end{proof}
We can now also look at some derived properties of the event space inhering from these defined properites
\begin{proposition}
    LEt $\mathcal{F}$ be an event space then
    \begin{enumerate}
        \item $\mathcal{F}$ is closed under finite union
        \item $\mathcal{F}$ is closed under finite intersection
        \item $\mathcal{F}$ is closed under countable intersection
    \end{enumerate}
\end{proposition}
\begin{proof}
    \begin{enumerate}
        \item Let $A_1,\dots,A_n \in \mathcal{F}$. Set $A_j = \emptyset,j > n$. therefor For all $i \in \mathbb{N^+},A_i \in \mathcal{F}$
        \[\bigcup_{j=1}^nA_j = \bigcup_{j=1}^\infty A_j \in \mathcal{F}\]
        \item LEt $A_1, \dots , A_n \in \mathcal{F}$. By demorgans law we may state 
        \[\bigcap_{j=1}^n A_j = \left(\bigcup_{j=1}^n A^C\right)^C\]
        By the closure of $\mathcal{F}$ under complements and under finite union we can say this finite intersection is in $\mathcal{F}$
        \item For the infinite case we apply the same argument we just used only swapping finite for infinite 
    \end{enumerate}
\end{proof}
\section{Lecture 6 - Probability measure}
\subsection{Probability measure}
\begin{definition}
    Given samples and event spaces $\Omega,\mathcal{F}$ a function $\mathbb{P} : \mathcal{F} \to \mathbb{R}$ is a probability measure if
    \begin{enumerate}
        \item For all $x \in \mathcal{F},\mathbb{P}(x) \in [0,1]$
        \item $\mathbb{P}(\Omega) = 1$
        \item For all $m,n$ such that $m \ne n,A_n \cap A_m = \emptyset$ then
        \[\mathbb{P}\left(\bigcup_{j=1}^\infty A_j\right) = \sum_{j=1}^\infty \mathbb{P}(A_j)\] 
    \end{enumerate}
\end{definition}
\begin{proposition}
    Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. We can make then the following propoistions about $\mathbb{P}$
    \begin{enumerate}
        \item $\mathbb{P}(\emptyset) = 0$
        \item if $A,B \in \mathcal{F}$ and $A \subseteq B$ then $\mathbb{P}(B - A) = \mathbb{P}(B) - \mathbb{P}(A)$
        \item For all $A \in \mathcal{F},\mathbb{P}(A^C) = 1 - \mathbb{P}(A)$
    \end{enumerate}
\end{proposition}
\begin{proof}
    \begin{enumerate}
        \item For all $n \ge 1$ let $A_n = \emptyset$. Therefore we can state $\bigcup_{n=1}^\infty A_n = \emptyset$
        \[\mathbb{P}(\emptyset) = \mathbb{P}\left(\bigcup_{n=1}^\infty A_n\right) = \sum_{n=1}^{\infty}\mathbb{P}A_n = \sum_{n=1}^{\infty}\mathbb{P}(\emptyset)\]
        This only holds if $\mathbb{P}(\emptyset) = 0$
        \item Using the same way we proved closure of finite unions in the event space we may prove a finite additivity for disjpin sets. This fact will be assumed here.
        Let $B = (B - A) \cup B$. By the definition of set difference we know that $(B - A) \cap A = \emptyset$. This allows us to apply finite additivity
        \[\mathbb{P}(B) = \mathbb{P}(B - A) + \mathbb{P}(A)\]
        \item $\mathbb{P}(A^C) = \mathbb{P}(\Omega - A) = \mathbb{P}(\Omega) - \mathbb{P}(A) = 1 - \mathbb{P}(A)$
    \end{enumerate}
\end{proof}
\subsection{Principle of inclusion Exclusion}
\begin{proposition}
    The Principle of Inclusion Exclusion is as follows. Let $(\Omega,\mathcal{F},\mathbb{P})$ be a probability space. Then for $A_1,\dots,A_n \in \mathcal{F}$
    \[\mathbb{P}\left(\bigcup_{k=1}^n A_k \right) = \sum_{k=1}^{n}\left((-1)^{k+1}\sum_{2 \le i_1 < \dots < i_k \le n }\mathbb{P}(A_{i_1} \cap \dots \cap a_{i_k})\right)\] 
\end{proposition}
\begin{proof}
    A proof sketchfor $n = 2$ is given here
    \[A \cup B = (A - A \cap B) \cup (A \cap B) \cup (B - A \cup B)\]
    By application of finite additivity PIE for $n = 2$ may be gotten. 
\end{proof}
\begin{proposition}
    If $(\Omega,\mathcal{F},\mathbb{P})$ is a propbabilty space then if $A,B \in \mathcal{F}$ and $A \subseteq B$ Then $\mathbb{P}(A) \le \mathbb{P}(B)$
\end{proposition}
\begin{proposition}
    Booles inequality : If $(\Omega,\mathcal{F},\mathbb{P})$ is a propbabilty space then for a list $A_1,\dots,A_n \in \mathcal{F}$ then
    \[\mathbb{P}\left(\bigcup_{k=1}^n A_n\right) \le \sum_{k=1}^{n}\mathbb{P}(A_n)\] 
\end{proposition}
\begin{proof}
    By induction on $n$
    \begin{itemize}
        \item Base case $n = 2$. $\mathbb{P}(A_1 \cup A_2) = \mathbb{P}(A_1) + \mathbb{P}(A_2) - \mathbb{P}(A_1 \cap B_2) \le \mathbb{P}(A_1) + \mathbb{P}(A_2)$
        \item Assume its true for some $n = k$.
        \begin{align*}
            \mathbb{P}(\bigcup_{j=1}^{k+1}A_j) &= \mathbb{P}(\bigcup_{j=1}^{k}A_j \cup A_{k+1}) \\
            &= \mathbb{P}(\bigcup_{j=1}^{k}A_j) + \mathbb{P}(A_{k+1}) - \mathbb{P}(\bigcup_{j=1}^{k}A_j \cap A_{k+1}) \\
            &\le \mathbb{P}(\bigcup_{j=1}^{k}A_j) + \mathbb{P}(A_k+1) \\
            &\le \sum_{j=1}^{k+1}\mathbb{P}(A_j)
        \end{align*} 
    \end{itemize}
\end{proof}
\section{Lecture 7 - Conditional Probability}
Suppose we are doing an experiment and an we have knowledge that an event $B$ has happened. Knowing this how can we find the probability that another event $A$ has happened. We call theis the prbability of $A$ given $B$ with this event denoted as follows
\[\mathbb{P}_B(A) = \mathbb{P}(A|B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}\]
\begin{proposition}
    Let $(\Omega,\cal{F},\mathbb{P})$ be a probability space and let $B \in \cal{F}$ Define $\mathbb{P}_B : \cal{F} \to \mathbb{R}$ as $\mathbb{P}_B(A) = \mathbb{P}(A|B)$. $\mathbb{P}_B$ is a probability measure
\end{proposition}
\begin{proof}
    There are three propterites to be checked.
    \begin{enumerate}
        \item It is known that $\mathbb{P}(A) \in [0,1]$ for all $A \in \cal{F}$. We also know that for this $A$, $A \cap B \in \mathcal{F}$. This means that $\mathbb{P}(A \cap B)$ is defined. We know that $\mathbb{P}(A \cap B) \le \mathbb{P}(B)$ Therefore 
        \[\frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} \in [0,1]\]
        \item \[\mathbb{P}_B(\Omega) = \frac{\mathbb{P}(B \cap \Omega)}{\mathbb{P}(B)} = 1\]
        \item The next property to check is coiuntable additivity. Let for all $n,A_n \in \cal{F}$ and let them all be pariise disjoint.
        \begin{align*}
            \mathbb{P}_B(\bigcup_{n=1}^\infty A_n) &= \frac{\mathbb{P}_B(\bigcup_{n=1}^\infty A_n \cap B)}{\mathbb{P}(B)} \\
            &= \frac{1}{\mathbb{P}(B)}\mathbb{P}(\bigcup_{n = 1}^\infty A_n \cup B) \\
            &= \sum_{n=1}^{\infty} \frac{\mathbb{P}(A_n \cup B)}{\mathbb{P}(B)} \\
            &= \sum_{n=1}^{\infty}\mathbb{P}_B(A_n)
        \end{align*}
        This assumed we were able to aplpy countable additivity to the orginal measure which requires $A_n \cap B$ to be pariwise disjoint
        \[(A_n \cap B) \cap (A_m \cap B) \subseteq A_n \cap A_m = \emptyset\] 
    \end{enumerate}
\end{proof}
This equation leads us to the multiplication rule 
\begin{theorem}
    Multiplication rule : $\mathbb{P}(A_1 \cap \cdots \cap A_n) = \mathbb{P}(A_1)\mathbb{P}(A_1|A_2)\mathbb{P}(A_3|A_1 \cap A_2) \cdots$
\end{theorem} 
this is proven using an expansion of the law of consitionak probability
\section{Lectire 8 + 9 : Firther applications}
If we wanted to know the probability of an event $C$ happening. We can consider all of the disjoint cases in which it could happen and take some kind of weighted mean of all of these probabilities to find $C$. This is the law of toal probability. 
\begin{theorem}
    $\mathbb{P}(C_2) = \mathbb{P}(C_2|C_1)\mathbb{P}(C_1) + \mathbb{P}(C_2|C_1^C)\mathbb{P}(C_1^C)$
\end{theorem}
\begin{proof}
    Diue to the fact $(C_1 \cup C_2) = \Omega$ The event $C_2 = (C_2 \cap C_1) \cup (C_2 \cap C_1^C)$. Then by application of finite additivity and the law of conditoinal probability the law of total probability can be derived
\end{proof}
This result can be futher generalised
\begin{theorem}
    Law of Total probability: Let $\{B_n | n \in [[N]] \}$ be a partition of $\Omega$. We can say \[\mathbb{P}(A) = \sum_{n=1}^{N} \mathbb{P}(A|B_n)\mathbb{P}(B_n)\]  
\end{theorem}
The proof is done in the same way by the aprreciation of the union of $B_n = \Omega$ and then applying countable additivitty and the laws of consitional probability.
\section{Lecture 10 - Random Variables}
Consider having done a random experiment which is quite complex as is the sample scpase $(\Omega)$ as such the indiviual events $(\cal{F})$ are also complex but these events are such that we know wether they have happened or not. 

Very often we wish to abstract these elements of $\Omega$ to something much simpler i.e something that has a numerical value given by the random process.

We can express this random variable as a function $X : \Omega \to \mathbb{R}$. This course will only consider random variables into the real numbers.
\begin{definition}
    Random Variable: Let $(\Omega,\cal{F},\mathbb{P})$ be a probability space. A real-valued random variable is a function $X:\Omega \to \mathbb{R}$ such that $\{\omega \in \Omega | X(\omega) \le a\} \in \cal{F}$ for all $a \in \mathbb{R}$ (This says that specifying conditions via $X$ gives an event that we can determine wether it has happened or not) 
\end{definition}
\begin{example}
    Consider rolling tow dice. You win money given by given by the greater value amongst the dice rolled. In this case
    \[\Omega = \{1,2,3,4,5,6\}^2\]
    \[X(x,y) = max(x,y)\]
    It can be seen that using the random varable $X$ simplifies the outcomes in $\Omega$
    \[\mathbb{P}(X = \overline{y}) = \mathbb{P}(\omega \in \Omega | X(\omega) = 5) = \frac{1}{5}\]
\end{example}
We can see at the end we use a condition on $X$ in order to specify an event. Intead in an inequality an equality was used but this can be shown to be inside of $\mathcal{F}$ by closere of $\cal{F}$ under set difference

We can consider the a new probability measure on $\mathbb{R}$ induced by the random variable $X$ and if this is all we care about we can leave the old prbability space behond and only cosider $\mathbb{R}$ as our sample space
\begin{definition}
    Distrobution: The distrobution of a random variable $X$ is the probability measure on $\mathbb{R}$ given by 
    \[\mathbb{P}_X(B) = \mathbb{P}(\{\omega \in \Omega | X(\omega) \in B\}\]
    such that $B \in \mathbb{R}$
\end{definition} 
\begin{example}
    Cont. $\mathbb{P}_X(\{k\}) = \frac{2k-1}{36}$ for $k = 1,2,3,4,5,6$ 
    
    otherwise $\mathbb{P}(\mathbb{R} \setminus \{1,2,3,4,5,6\}) = 0$
\end{example}
\begin{definition}
    Event Space: We will usually denote the envent space on $\mathbb{R}$ denoted $\mathcal{B}(\mathbb{R})$ contains singletons $\{x\}$ and intervals $(a,x]$ And is close under countable set operations as is $\mathcal{F}$. We have no need to be able to lost elements.
\end{definition}
\begin{definition}
    The triplet $(\mathbb{R},\mathcal{B}(\mathbb{R}),\mathbb{P}_X)$ is a simpler derived probability space.
\end{definition}
\begin{proposition}
    The function $\mathbb{P}_X$ is a proabbility measure on $R$
\end{proposition}
\begin{proof}
    We must check the three conditions of probability measure
    \begin{enumerate}
        \item $\mathbb{P}_X(B) = \mathbb{P}(\{\omega \in \Omega | X(\omega) \in B\}) \in [0,1]$
        \item $\mathbb{P}_X(\mathbb{R}) = \mathbb{P}(\{\omega \in \Omega | X(\omega) \in \mathbb{R}\}) = \mathbb{P}(\Omega) = 1$
        \item Suppose $B_1,B_2,\dots \in \mathcal{B}(\mathcal{R})$ are disjoint.
        \begin{align*}
            \mathbb{P}_X\left(\bigcup_{n=1}^\infty B_n\right) &= \mathbb{P}(\{\omega \in \Omega | X(\omega) \in \bigcup_{n=1}^\infty B_n\}) \\
            &= \mathbb{P}(\bigcup_{n=1}^\infty\{\omega \in \Omega | X(\omega) \in  B_n\}) \\
            &= \sum_{n=1}^{\infty}\mathbb{P}(\{\omega \in \Omega | X(\omega) \in  B_n\}) \\
            &= \sum_{n=1}^{\infty} \mathbb{P}_X(B_n)
        \end{align*}
        This uses thhe facts that pre-image of the union is the union of the pre-image; that pre-image of disjoint sets are disjoint,
    \end{enumerate}
\end{proof}
\section{Lecture 11}
\begin{definition}
    Let $(\mathbb{R},\mathcal{B}(\mathbb{R}),\mathbb{P}_X)$ be an induced probability space. We may it is discrete if there exist a countable or finite set $S \subseteq R$ such that $\mathbb{P}(X \in \mathbb{R} \setminus S) = 0$ 
\end{definition}
\begin{definition}
    Let $(\mathbb{R},\mathcal{B}(\mathbb{R}),\mathbb{P}_X)$ be a probility spacee and $X$ be drv we define the prbability mass function $p_X : \mathbb{R} \to [0,1]$ as follows
    \[p_X(x) = \mathbb{P}_X(x)\]
    This is a simpler function as it allwos us to investigate individual probabilities instead of those fo a set.
\end{definition}
\begin{definition}
    Let $(\mathbb{R},\mathcal{B}(\mathbb{R}),\mathbb{P}_X)$ be a probability space and $X$ be a drv. We may define the discrete support of $X$ or $\mathbb{P}_X$ as follows 
    \[\{x \in \mathbb{R} | p_X(x) > 0\}\]
\end{definition}
\begin{proposition}
    Let $X$ be a drv and $D_X$ be its support
    \[\mathbb{P}_X(B) = \sum_{x \in B \cap D^C}p_X(x)\]
\end{proposition}
\begin{proof}
    We know there is a $S \subseteq \mathbb{R}$ such that $\mathbb{P}_X(S) = 0$. From here we can determine that $D^C$ is countable as $D \subseteq  S$.
    We may say that 
    \[P_X(B) = P_X(B \cap D) + P_X(B \cap D^C)\]
    The second term has to be zero as $B \cap D^C \subseteq D^C$ so $0 \le P_X(B \cap D^C) \le P_X(D^C) \le 0$
    We can then evaluate as follows
    \begin{align*}
        P_X(B) &= P_X(B \cap D) \\
        &= P_X\left(\bigcup_{x \in B \cap D}\{x\}\right) \\
        &= \sum_{x \in B \cap D}P_X(\{x\}) \\
        &= \sum_{x \in B \cap D}p_X(x)
    \end{align*}  
\end{proof}
From here we have the fact that $p_X$ caontains all the information of $\mathbb{P}_X$ as the latter can be reconstructed from the fomrer.
\section{Lecture 12}
As said before $D_X$ doest necessarilly equal $S$
\begin{example}
    Consider rolling a die. $\Omega = \{1,2,3,4,5,6\}$, $X:\Omega \to \mathbb{R}, X(k) = k$.
    From here we get the definition of $D_X = \{1,2,3,4,5,6\}$ which is a suitable candidate for $S$. But this is not the only choice. Any countable extention of $D_X$ is also a candidate for example $S = \mathbb{N}$ as there are no elements in $\mathbb{N}^C$ that are in $D_X$ so $\mathbb{P}_X(\mathbb{N}^C) = 0$
\end{example}
\begin{definition}
    A function $f : \mathbb{R} \to [0,1]$ is a function is the set $D$ defined as follows
    \[D = \{\{x | f(x) > 0\}\}\]
    Is countable and $\sum_{k \in D}f(k) = 1$
\end{definition}
This gives us a definition of a probability mass function without already having a space. We can however construct a space from here.
\begin{proposition}
    LEt $f$ be a proabbaility mass function. Then there exist a probability space $(\Omega,\mathcal{F},\mathbb{P})$ and a drv $X$ such that $p_X = f$
\end{proposition}  
\begin{proof}
    Take $D$ to be the discrete support of $f$. Let $\Omega = \mathbb{R},\mathcal{F} =\mathcal{B}(\mathbb{R}),\mathbb{P}(B) = \sum_{x \in B \cap D}f(x)$
    
    We now need to prove that $\mathbb{P}$ is a measure
    \begin{itemize}
        \item \[\mathbb{P}(\mathbb{R}) = \sum_{k \in \mathbb{R} \cap D}f(k) = \sum_{x \in D}f(x) =  1\]
        \item $\mathbb{P} \in [0,1]$
        \item Suppose $A_1,\dots,A_n \in \mathcal{F}$ are all pairwise disjoint.
        \begin{align*}
            \mathbb{P}\left(\bigcup_{n = 1}^{\infty}A_n\right) &= \sum_{k \in \left(\bigcup_{n = 1}^{\infty}A_n\right) \cap D}f(x)\\
            &= \sum_{k \in \left(\bigcup_{n = 1}^{\infty}A_n \cap D\right)}f(x) \\
            &= \sum_{n = 1}^{\infty} \sum_{x \in A_n \cap D}f(x) \\
            &= \sum_{n = 1}^{\infty} \mathbb{P}(A_n)
        \end{align*}
    \end{itemize}
    Now we need to construct the DRV. LEt $X(x) = x$. $X$ has the right domain and codomain. and we can also say $\mathbb{P} = \mathbb{P}_X$. We also need to check it has an opporopriate countable set $S$ For this we may try D.
    \[\mathbb{P}_X(\mathbb{R} \setminus D) = \mathbb{P}_X(D^C) = \mathbb{P}(D^C) = \sum_{x \in D^C \cap D}f(x) = 0\]
    Finally we need to check $f$ is the probabilit mass function for $X$. If $x \in D$ 
    \[p_X(x) = \mathbb{P}_X(\{x\}) = \mathbb{P}(\{x\}) = \sum_{x \in \{x\} \cap D}f(x) = f(x)\]
    Otherwise 
    \[p_X(x) = \mathbb{P}_X(\{x\}) = \mathbb{P}(\{x\}) = \sum_{x \in \{x\} \cap D}f(x) = \sum_{x \in \emptyset}f(x) = 0 = f(x)\]
\end{proof}
Now lets look at some experiments that are discrete spaces.
\begin{example}
    Imagine tossing a $p$-coin which is a coin where the probability of heads is $p$. We may construct our space as follows.
    $\Omega = \{H,T\},\mathbb{P}(\{H\}) = p,\mathbb{P}(\{T\}) = 1 - p$. We may define $X: \Omega \to \mathbb{R}$ as $X(H) = 1,X(T) = 0$. We may then say $X \sim \text{Bernoulli}(p)$
\end{example}
\begin{definition}
    Where $p \in [0,1]$ we may say $X \sim \text{Bernoulli}(p)$ if
    \[p_X(x) = \begin{cases}
        p & x = 1 \\
        1 - p & x = 0 \\
        0 & \text{otherwise}
    \end{cases}\]
\end{definition}
\begin{example}
    Consider another experiment where we toss the $p$-coin till we gewt heads. Let $X$ map to the number of tosses and $\Omega$ be the set of sequences of tails which then end in heads.
    \[\mathbb{P}(\{\underbrace{T \dots T}_{k \text{ times}}H\}) = (1-p)^kp\]
    \[X(\{\underbrace{T \dots T}_{k \text{ times}}H\}) = k+1\]
\end{example}
\begin{definition}
    We can say $X \sim \text{Geom}(p)$ if
    \[p_X(k) = \begin{cases}
        p(1-p)^k-1 & k \in \mathbb{N} \\
        0 & \text{Otherwise}
    \end{cases}\]
\end{definition}
\begin{definition}
    $X \sim Bin(n,p)$ where $n \in \mathbb{N},p \in [0,1]$ if 
    \[p_X(k) = \begin{cases}
        \binom{n}{x}p^x(p-1)^{(n-x)} & k \in \{0,\dots,n\} \\
        0 & \text{Otherwise}
    \end{cases}\]
\end{definition}
\section{Lecture 13}
Expectation: Sometimes we want to consider question such as what is the average outcome of a roll of a dice. in order to do this we may calculuate some form of a weighted mean.
\[\frac{1}{6}(1 + 2 + 3 + 4 + 5 + 6) = 3.5\]
We call this number the expectation of reolling a dice
\begin{definition}
    Consider a discrete random variable $X$ with a suppoer $D$ and a mass function $p_X$ We define the expectation of $X$ denoted $\mathbb{E}(X)$ defined as follows
    \[\mathbb{E}(X) = \sum_{x \in D} xp_X(x)\]
    As long as it converges absolutley (sum of absolute values converges), Otherwise the expectation is undefined
\end{definition}
\begin{definition}
    A drv $X$ with support $D$ and probability mass function $p_X$ is integrable if the sum
    \[\sum_{x \in D} |x|p_X(x)\]
    converges
\end{definition}
\begin{example}
    Consider $X \sim B(n,p)$
    \begin{align*}
        \mathbb{E}(X) &= \sum_{k = 0}^{n}k\binom{n}{k}p^k(1-p)^{n-k} \\
        &= \sum_{k = 1}^{n}n\binom{n-1}{k-1}p^k(1-p)^{n-k} \\
        &= n\sum_{j = 0}^{n - 1}\binom{n - 1}{j}p^{j+1}(1-p)^{n-j-1} \\
        &= np\sum_{j = 0}^{n - 1}\binom{n - 1}{j}p^{j}(1-p)^{n-j-1} \\
        &= np(p + (1-p))^{n-1} \\
        &= np
    \end{align*}
\end{example}
Comsider now fixing this value $\lambda = np$. This leads us to the following experiment. We may consider tossing the $p$-coin $n$ times such that the expected number of heads is fixed.
\[\mathbb{P}(X = k) = \binom{n}{k}p^k(1-p)^{n-k} = \frac{n!}{k!(n-k)!}\left(\frac{\lambda}{n}\right)^k \left(1 - \frac{\lambda}{n}\right)^{n-k} = \frac{\lambda^k}{k!} \frac{n!}{n^k (n-k)!} \left(1 - \frac{\lambda}{n}\right)^{n} \left(1 - \frac{\lambda}{n}\right)^{-k}\]
Taking the limit of $n \to \infty$ we get this is equal to
\[\frac{\lambda^k}{k!}e^{-\lambda}\]
\begin{definition}
    Poission Distobution : $X \sim Poiss(\lambda)$ if we may say that 
    \[p_X(x) = \frac{\lambda^k}{k!}e^{-\lambda}\] 
\end{definition}
\begin{example}
    LEt $X$ be a drv as a  indicator function of a set $A \in \mathcal{F}$. We can say here $E[X] = \mathbb{P}(A)$
\end{example}
\begin{example}
    $X \sim Geom(P)$
    \begin{align*}
        E[x] &= \sum_{n = 1}^{\infty}n(1-p)^{n-1}p \\
        &= p\sum_{n = 1}^{\infty}n(1-p)^{n-1} \\
        &= p\sum_{n = 1}^{\infty}\frac{d}{d(1-p)}(1 - p)^{n} \\
        &= p\frac{d}{d(1-p)}\sum_{n = 1}^{\infty}(1 - p)^{n} \\
        &= p\frac{d}{d(1-p)}\frac{1}{1 - (1 - p)} \\
        &= p \frac{-1}{(1 - (1-p)^2)} \\
        &= p \frac{1}{p^2} \\
        &= \frac{1}{p}
    \end{align*}
\end{example}
\section{Lecture 15}
\subsection{Expectation of functions}
One interpretation of the expectation is as the centre of mass of the mean of a distrobution. This allows the expectation to act as a mean.

If we have a 2 dimensional random variable $Z = (X,Y)$ We can say that $E[Z] = (E[X],E[Y])$
Sometimes we tranform a ditrobution by a function $g : \mathbb{R} \to \mathbb{R}$ and we still want to find these expectations. We have been able to do this for linear functions but we may want to do this for $x^2$ as this is useful for variance.

\begin{example}
    Consider $X \sim Geom(p)$
    \begin{align*}
        E[X^2] &= \sum_{n = 1}^{\infty} n^2 (1-p)^{n - 1}p \\
        &= p\sum_{n = 0}^{\infty}nx^{n - 1} + p\sum_{n = 0}^{\infty}n(n - 1)x^{n - 1} , x = 1 - p\\
        &= p \sum_{n = 0}^{\infty} \frac{d}{dx}x^n + px\sum_{n = 0}^{\infty}n(n - 1)x^{n - 2}\\
        &= p \frac{d}{dx}\left(\sum_{n = 0}^{\infty}x^n\right) + px \sum_{n = 0}^{\infty} \frac{d^2}{dx^2}x^n \\
        &= p \frac{d}{dx}\left(\frac{1}{1 - x}\right) + px \frac{d^2}{dx^2}\left(\sum_{n = 0}^{\infty}x^n\right) \\
        &= p\frac{1}{(1 - x)^2} + px\frac{2}{(1 - x)^3} \\
        &= \frac{1}{p} + 2\frac{1 - p}{p^2}\\
        &= \frac{2 - p}{p^2}
    \end{align*}
\end{example}
\begin{example}
    Consider $X \sim Geom(p)$

    For what values of t is $e^{tx}$ integrable (Sum for expectation exists). As such compute $E[e^{tX}]$.
    \begin{align*}
        E[e^{tX}] &= \sum_{n = 1}^{\infty}e^{tn} p (1 - p)^{n - 1} \\
        &= pe^t \sum_{n = 1}^{\infty}(e^t (1 - p))^{n - 1} \\
        &= pe^t \sum_{k = 0}^{\infty}(e^t (1 - p))^k \\
        &= \frac{pe^t}{1 - e^t(1 - p)} \\
        &= \frac{p}{e^{-t} + p - 1} 
    \end{align*}
    Not this is only defined where $e^t(1-p) < 1$ so $t < \ln\frac{1}{1 - p}$
\end{example}
Consider for where it isnt integrable. This means that there is no expectation. Further if a random varibale does have an expectation a function of the random variable (even $x^2$) may not hadve a defined expectation.

In general We may say if you have a DRV $X$ transformed by a function $g : \mathbb{R} \to \mathbb{R}$ We may say the following
\[E[g(X)] = \sum_{x \in D_X}g(x)p_X(x)\]
\subsection{Variance}
Variance is used to measure the dispersion of a random variable
\begin{definition}
    (Square integrable r.v.) : A DRV $X$ is square integrable if $X^2$ is integrable.
\end{definition}
\begin{definition}
    (Variance): Consider a Square integrable random variable $X$. Let $\mu := E[X]$
    \[Var(x) = E[(x - \mu)^2]\]
\end{definition}
From here we can note that
\[Var(X) = E[(X - \mu)^2] = E[X^2 - 2\mu X + \mu^2] = E[X^2] - 2\mu E[X] + \mu^2 = E[X^2] - \mu^2 \]
\begin{example}
    Consider $X \sim Poisson(\lambda)$
    \[Var(X) = E[X^2] - E[X]^2 = \lambda + \lambda^2 - \lambda^2 = \lambda\]
\end{example}
\begin{example}
    Consider $X \sim Geom(p)$
    \[Var(X) = E[X^2] - E[X]^2 =\]
\end{example}
We may note that the follwwing identity holds
\[Var(ax) = a^2Var(x)\]
We also can see then that the units of the variance are not therefore the same as the expexctation but instead is the square of the unit as such we introduce the following.
\subsection{Standard Deviation}
\begin{definition}
    Let $X$ be a square integrable DRV then we may say the following
    \[\sigma(X) = \sqrt{Var(X)}\] 
\end{definition}
\section{Multivariate Discrete Dictrobutions}
Sometimes you wish to investigate a combination of thwo DRVs. The combination of the to can mbe made into one in of itself
\subsection{Probability Mass functions}
\begin{definition}
    Given two DRVs we can define the joint probability mass function as follows 
    \[p_{X,Y}(x,y) = \mathbb{P}(X=x,Y=y)\]
    Or more in the proper times
    \[\mathbb{P}(\{\omega \in \Omega|X(\omega) = x,Y(\omega) = y\})\]
\end{definition}
Sometimes you wish to recover $p_X$ from a jpoint probability distrbution. This is called the marginal probability and can be computes as follows
\[p_X(x) = \sum_{y \in D_Y}p_{X,Y}(x,y)\]
\subsection{Expectation}
\begin{proposition}
    Given two DRVs $X,Y$ and a function $g : \mathbb{R}^2 \to \mathbb{R}$ we may say that 
    \[E(g(X,Y)) = \sum_{x \in D_X} \sum_{y \in D_Y} g(x,y)p_{X,Y}(x,y)\]
\end{proposition}
This can be formally proven by constructing a new DRV $Z = g(X,Y)$. It is important to noe when constructing a probability measure on $Z$ we are not guaranteed that $g$ is an injection so there can be multiple pairs $X,Y$ that can give the same value of $Z$
\subsection{Indepedance}
\begin{definition}
    We can say two DRVs $X,Y$ are independant if 
    \[p_{X,Y}(x,y) = p_X(x)p_Y(y)\]
\end{definition}
The defintions of pairwise and mutual independance fall out similarly to before. It follows that if two DRVs are independant we can calculate the expectation of the prodict as follows
\[E(XY) = E(X)E(Y)\]
This iextends to the product of more than one DRV. Similarly we can get a result for variance.
\[Var\left( \sum_{i = 1}^{n}X_i \right) = \sum_{x = 1}^{n} Var(X_i)\]
Both of these have proofs which are omitted.
\section{Law of Averages}
\begin{theorem}
    Let $(X_i)$ be a collection of pariwise independant discrete random variables all bearing the same mean and variance $\mu,\sigma$. We may say then that
    \[\mathbb{P}\left( \mu - a \le \frac{X_1 + \cdots + X_n}{n} \le \mu + a \right) \ge 1-\frac{\sigma^2}{a^2n}\] 
\end{theorem}
This essentially encodes the idea that with more and more trials the outcome becomes more and more clustered around the true mean the mean of outcomes becomes.
\section{Covariance}
Sometimes we want to investigate the how two random variable vary together. though expansion by the definition we can note
\[Var(X + Y) = Var(X) + Var(Y) + 2E[(X - E[X])(Y - E[Y])]\]
From here we can gain the following definition
\begin{definition}
    We can define the covariance of two DRV's as follows
    \[Cov(X,Y) = E[(X - E[X])(Y - E[Y])]\]
\end{definition} 
If we have that $Cov(X,Y) = 0$ then we say the two varibles are uncorrelated. All independant variables are uncorrelated
Covariance has a few simple identities
\[Cov(X,Y) = Cov(Y,X)\]
\[Cov(X,X) = Var(X)\]
Covariance comes with a number of useful algebraic properties.
\begin{proposition}
    Suppose $X,Y,Z$ are square integrable
    \[Cov(aX + bY,Z) = aCov(X,Z) + bCov(Y,Z)\]
\end{proposition}
This propertiy naturally extends as 
\begin{proposition}
    \[Cov\left(\sum_{j = 0}^{n}a_jX_j,\sum_{k = 0}^{m} b_kY_k\right) = \sum_{j=0}^{n}\sum_{k = 0}^{m}a_jb_kCov(X_j,Y_k)\]
\end{proposition}
We can also generlaise the definition of covariance from above aswell
\begin{proposition}
    \[Var\left( \sum_{k = 1}^{n}X_k \right) = \sum_{x = k}^{n}Var(X_k) + 2\sum_{1 \le j \le k \le n} Cov(X_j,X_k)\]
\end{proposition}
\section{Chebyshevs Inequality}
\subsection{Markovs Inequality}
\begin{theorem}
    (Markovs Inequality). Let $X$ be a non negative integrable DRV we may say
    \[\mathbb{P}(X \ge x) \le \frac{E[X]}{x}\]
    For all $x > 0$ 
\end{theorem}
\begin{proof}
    Fix $x > 0$ then we can define a radnom variable $Y$ as follows
    \[Y = \begin{cases}
        x & X \ge x \\
        0 & \text{Otherwise}
    \end{cases}\]
    It is clear that $X \ge Y$ so we may also then say $E[X] \ge E[Y]$
    We can also note that the probability mass function is given as 
    \begin{align*}
        p_Y(x) &= \mathbb{P}(X \ge x) \\
        p_Y(0) &= \mathbb{P}(X < x)
    \end{align*}
    as such we can do the following
    \begin{align*}
        E[X] &\ge E[Y] \\
        &\ge 0p_Y(0) + xp_Y(x) \\
        &\ge xP(X \ge x)
    \end{align*}
    Which gives the desired inequality
\end{proof}
\subsection{Chebyshevs Inequality}
\end{document}
